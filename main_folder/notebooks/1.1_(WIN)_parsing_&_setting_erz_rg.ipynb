{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. ПРЕДВАРИТЕЛЬНАЯ НАСТРОЙКА ДАННЫХ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Настройка библиотек"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1.1 Библиотеки для работы с директориями"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1.2 Библиотеки для работы с данными"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Для обработки таблиц и работы с массивами\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import openpyxl\n",
    "import json\n",
    "\n",
    "import warnings\n",
    "\n",
    "# Отключение предупреждений, возникающих при чтении данных\n",
    "warnings.filterwarnings('ignore', category=UserWarning, module='openpyxl.styles.stylesheet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1.3 Библиотеки для работы с парсингом"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Библиотеки для парсинга (без открытия браузера)\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import Request, urlopen\n",
    "import requests\n",
    "\n",
    "# Библиотеки для парсинга (с открытием браузера)\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options                         # <- для настройки параметров браузера \n",
    "from selenium.webdriver.chrome.service import Service as ChromeService        # <- для настройки параметров браузера \n",
    "from selenium.webdriver.common.by import By                                   # <- для поиска элемента по условию (кнопки прогрузки)\n",
    "from selenium.webdriver.support.ui import WebDriverWait                       # <- таймер для браузера\n",
    "from selenium.webdriver.support import expected_conditions as EC              # <- для ожидания определенных условий на странице\n",
    "from selenium.common.exceptions import TimeoutException, WebDriverException   # <- чтобы избежать ошибки в случае истечения времени\n",
    "\n",
    "# Библиотека для автоматического обновления/скачивания/удаления драйвера\n",
    "from webdriver_manager.chrome import ChromeDriverManager"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1.4 Прочие библиотеки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import sleep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1.5 Импорт кода из папки Source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib.util\n",
    "\n",
    "module_name = 'parameters_erz_parsing'\n",
    "module_path = os.path.abspath('../source/parameters_erz_parsing.py')\n",
    "\n",
    "spec = importlib.util.spec_from_file_location(module_name, module_path)\n",
    "parameters_erz_parsing = importlib.util.module_from_spec(spec)\n",
    "spec.loader.exec_module(parameters_erz_parsing)\n",
    "\n",
    "from source.parameters_erz_parsing import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Настройка директорий"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "this_directory = os.getcwd()\n",
    "\n",
    "dipl_directory = this_directory.split('main_folder')[0]\n",
    "data_directory = dipl_directory + 'raw_data'\n",
    "\n",
    "# В Windows подключение к данным выглядит так:\n",
    "xlsx_directory = data_directory + '\\\\excel\\\\'\n",
    "dcsv_directory = data_directory + '\\\\csv\\\\erz\\\\'\n",
    "json_directory = data_directory + '\\\\json\\\\erz\\\\'\n",
    "\n",
    "# Директория выгруженных и первично обработанных данных\n",
    "data_clean_directory = this_directory.split('notebooks')[0] + 'data'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Пересохранение данных из excel в csv (если это требуется)\n",
    "ВАЖНО: помимо просто пересохранения файла ещё вычленяем ссылки на ЖК для парсинга"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция пересохранения файла\n",
    "def excel_to_csv(name_file_excel: str, page_save: str, name_file_csv: str):\n",
    "    \n",
    "    # -----------------------------------------------------------------\n",
    "    # выбираем файл \n",
    "    try:\n",
    "        wb = openpyxl.load_workbook(name_file_excel, data_only=True)\n",
    "    except Exception as e:\n",
    "        print(f'Ошибка при загрузке файла .xlsx: {e}')\n",
    "        sys.exit(1)\n",
    "    \n",
    "    # -----------------------------------------------------------------\n",
    "    # выгружаем лист\n",
    "    try:\n",
    "        ws = wb[page_save]\n",
    "    except KeyError:\n",
    "        print(f\"Лист с именем '{page_save}' не найден в файле.\")\n",
    "        sys.exit(1)\n",
    "    \n",
    "    # -----------------------------------------------------------------\n",
    "    # из столбца с гиперссылками вытаскиваем ссылки на ЖК\n",
    "    column_letter = 5\n",
    "    hyperlinks = []\n",
    "    \n",
    "    for row in ws.iter_rows(min_row=2, min_col=column_letter, max_col=column_letter):\n",
    "        cell = row[0]\n",
    "        cell_value = cell.value if cell.value else \"\"\n",
    "        hyperlink = cell.hyperlink.target if cell.hyperlink else \"\"\n",
    "        hyperlinks.append((cell_value, hyperlink))\n",
    "    \n",
    "    # -----------------------------------------------------------------\n",
    "    # пересохраняем файл\n",
    "    file_open = pd.read_excel(name_file_excel, sheet_name=page_save, engine='openpyxl')\n",
    "    \n",
    "    # Добавляем новые столбцы\n",
    "    file_open['Наименование ЖК'] = [item[0] for item in hyperlinks]\n",
    "    file_open['Ссылка на ЖК'] = [item[1] for item in hyperlinks]\n",
    "    \n",
    "    file_open.to_csv(name_file_csv, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = '01012025'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# excel_to_csv(xlsx_directory + 'top_gk_' + data + '_M.xlsx', 'Топ ЖК', dcsv_directory + 'top_gk_M.csv')\n",
    "# excel_to_csv(xlsx_directory + 'top_gk_' + data + '_MO.xlsx', 'Топ ЖК', dcsv_directory + 'top_gk_MO.csv')\n",
    "# excel_to_csv(xlsx_directory + 'top_gk_' + data + '_LO.xlsx', 'Топ ЖК', dcsv_directory + 'top_gk_LO.csv')\n",
    "# excel_to_csv(xlsx_directory + 'top_gk_' + data + '_SPB.xlsx', 'Топ ЖК', dcsv_directory + 'top_gk_SPB.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Обработка таблиц с топом ЖК"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4.1 Первичная обработка списка ЖК"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция очистки и преобразования таблицы для получения ссылок\n",
    "def update_table(df: str, to_save = True):\n",
    "\n",
    "    # -----------------------------------------------------------------\n",
    "    # <-- попытка прочитать файл\n",
    "    try:\n",
    "        pd_region = pd.read_csv(df)\n",
    "    except:\n",
    "        return None\n",
    "    \n",
    "    # -----------------------------------------------------------------\n",
    "    # <-- попытка запустить преобразвания наименований Застройщика\n",
    "    try:\n",
    "        pd_region['Застройщик'] = pd_region['Застройщик'].str.upper().str.replace('ГК ', '', regex=False)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    # -----------------------------------------------------------------\n",
    "    # <-- попыка избавиться от лишних столбцов\n",
    "    try:\n",
    "        pd_region = pd_region.drop(columns=['№', '+/-'])\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    # -----------------------------------------------------------------\n",
    "    # <-- сохранение файла, если то необходимо\n",
    "    if to_save:\n",
    "        pd_region.to_csv(df, index=False)\n",
    "    \n",
    "    # -----------------------------------------------------------------\n",
    "    # <-- возвращаем таблицу\n",
    "    return pd_region"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4.2 Выгрузка таблиц"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(dcsv_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_msk = update_table('top_gk_M.csv')\n",
    "csv_mo = update_table('top_gk_MO.csv')\n",
    "csv_spb = update_table('top_gk_SPB.csv')\n",
    "csv_lo = update_table('top_gk_LO.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4.3 Репрезентация таблиц"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_msk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_mo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_spb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_lo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. ПАРСИНГ ДАННЫХ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Класс парсинга с использованием Selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "'''\n",
    "===============================================================================\n",
    "ПАРСИНГ\n",
    "===============================================================================\n",
    "'''\n",
    "class ParsingSelenium():\n",
    "    \n",
    "    # ------------------------------------------------------------------------\n",
    "    ''' ПРЕДВАРИТЕЛЬНАЯ ПОДГОТОВКА '''\n",
    "    def __init__(self, headless = True):\n",
    "        \n",
    "        # Инициируем настройки для хрома\n",
    "        chrome_options = Options()\n",
    "        \n",
    "        if headless:\n",
    "            chrome_options.add_argument(\"--headless=new\")  # <-- Фоновый режим\n",
    "            chrome_options.add_argument(\"--disable-gpu\")   # <-- Отключение GPU (для headless)\n",
    "            chrome_options.add_argument(\"--no-sandbox\")    # <-- Отключение sandbox (для некоторых систем)\n",
    "        \n",
    "        service = ChromeService(ChromeDriverManager().install())\n",
    "        self.driver = webdriver.Chrome(service = service, options = chrome_options)\n",
    "    \n",
    "    \n",
    "    # ------------------------------------------------------------------------\n",
    "    ''' ФУНКЦИЯ ОТКРЫТИЯ ВЕБ-СТРАНИЦЫ ДЛЯ ПАРСИНГА '''\n",
    "    def _link_get(self, link: str) -> object:\n",
    "        return self.driver.get(link)\n",
    "    \n",
    "        \n",
    "    # ------------------------------------------------------------------------\n",
    "    ''' ФУНКЦИЯ ОТКРЫТИЯ СТРАНИЦЫ '''\n",
    "    def _process_retry(self, func, *args, retries = 3, **kwargs):\n",
    "        for attempt in range(1, retries + 1):\n",
    "            try:\n",
    "                return func(*args, **kwargs)\n",
    "            \n",
    "            except (TimeoutException, WebDriverException) as e:\n",
    "                print(f'Ошибка при загрузке данных: {e}')\n",
    "                print(f'Попытка {attempt} из {retries}...')\n",
    "                \n",
    "                if attempt < retries:\n",
    "                    sleep(2 ** attempt) # <-- Экспоненциальная задержка между попытками\n",
    "                else:\n",
    "                    raise               # <-- Поднимаем исключение, если все попытки неудачны\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Класс парсинга параметров ЖК"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "===============================================================================\n",
    "ПОИСК ИНФОРМАЦИИ ПО ЖК\n",
    "===============================================================================\n",
    "'''\n",
    "class ParsingERZ_ZHK():\n",
    "    \n",
    "    # ------------------------------------------------------------------------\n",
    "    ''' ПРЕДВАРИТЕЛЬНАЯ ПОДГОТОВКА '''\n",
    "    def _init_(self, tbl):\n",
    "        self.tbl = tbl\n",
    "        self.col_names = tbl['Наименование ЖК']\n",
    "        self.col_links = tbl['Ссылка на ЖК']\n",
    "        \n",
    "        self.dct_names = {}\n",
    "        for i in range(len(self.col_names)):\n",
    "            self.dct_names[self.col_names[i]] = self.col_links[i]\n",
    "            \n",
    "            \n",
    "    # ------------------------------------------------------------------------\n",
    "    ''' ФУНКЦИЯ ЗАПУСКА ПАРСИНГА '''\n",
    "    def _parsingZHK(self, objects: dict, timer = 10):\n",
    "        \n",
    "        # 1. Создание класса парсинга\n",
    "        SelPars = ParsingSelenium()\n",
    "        \n",
    "        # 2. Создание словаря с параметрами \n",
    "        parametersZHK = {}\n",
    "        \n",
    "        # 3. Цикл для каждого проекта\n",
    "        for zhk in objects:\n",
    "\n",
    "            print('~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~')\n",
    "            print(zhk)\n",
    "            \n",
    "            # --> добавление наименования ЖК в словарь\n",
    "            parametersZHK[zhk] = {}\n",
    "            \n",
    "            # --> создание ссылки\n",
    "            link = objects[zhk]\n",
    "            # --> ресурс сайта\n",
    "            mainSoup = SelPars._process_retry(SelPars._link_get, link)\n",
    "            \n",
    "            # --> введение параметра временной задержки\n",
    "            wait = WebDriverWait(SelPars.driver, timer)\n",
    "            \n",
    "            # --> пробуем найти параметры ЖК\n",
    "            try:\n",
    "                # --> пустые списки, которые необходимо заполнить параметрами, если они есть\n",
    "                rowTabs = []\n",
    "                rowVals = []\n",
    "                tries_count = 0\n",
    "                \n",
    "                # --> запуск цикла поиска парамеров\n",
    "                while (rowTabs == [] or rowVals == []) and tries_count <= timer:\n",
    "                \n",
    "                    # --> поиск таблицы \n",
    "                    webTableZhk = wait.until(EC.presence_of_element_located((By.XPATH, class_house)))\n",
    "            \n",
    "                    # --> поиск всех строк наименований параметров и их значений\n",
    "                    rowTabs = webTableZhk.find_elements(By.XPATH, class_name)\n",
    "                    rowVals = webTableZhk.find_elements(By.XPATH, class_values)\n",
    "                \n",
    "                    # --> иногда страницы не успевают прогрузиться, нужно подождать и попробовать снова\n",
    "                    if rowTabs == [] or rowVals == []:\n",
    "                        tries_count += 1\n",
    "                        sleep(5)\n",
    "                        \n",
    "                    else:\n",
    "                        tries_count = timer + 1\n",
    "                    \n",
    "                # --> возвращение всех параметров            \n",
    "                for i in range(len(rowTabs)):\n",
    "                    \n",
    "                    # параметры\n",
    "                    parameter_name = rowTabs[i].text\n",
    "                    parameter_value = rowVals[i].text.replace('\\n', ' ')\n",
    "                    \n",
    "                    # добавление в общий словарь\n",
    "                    parametersZHK[zhk][parameter_name] = parameter_value\n",
    "                    \n",
    "                    # принт параметра\n",
    "                    # print(' - ', rowTabs[i].text + ': ' + rowVals[i].text.replace('\\n', ' '))\n",
    "            \n",
    "            # ---------- ошибка при условии, что не найдено ----------\n",
    "            except TimeoutException:\n",
    "                print('Данные не найдены!')\n",
    "            \n",
    "            # print()\n",
    "            \n",
    "        return parametersZHK\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Запуск выгрузки для регионов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfs_regions = {\n",
    "#     'params_msk': csv_msk,\n",
    "#     'params_mo': csv_mo,\n",
    "#     'params_spb': csv_spb,\n",
    "#     'params_lo': csv_lo\n",
    "#     }\n",
    "\n",
    "# for region in dfs_regions:\n",
    "#     erz_zhk = ParsingERZ_ZHK(dfs_regions[region])\n",
    "#     erzZHKparams = erz_zhk._parsingZHK(erz_zhk.dct_names)  \n",
    "\n",
    "#     with open(json_directory + region + '.json', 'w', encoding='utf-8') as file:\n",
    "#         json.dump(erzZHKparams, file, ensure_ascii=False, indent=4) \n",
    "\n",
    "#     print('\\n==================================================')\n",
    "#     print(\"Data has been saved to '{}.json'\".format(json_directory + region))\n",
    "#     print('==================================================\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. ОБРАБОТКА ДАННЫХ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Выгрузка уникальных значений для каждого параметра (столбца)\n",
    "(необходимо для того, чтобы посмотреть, какие значения во что превращать)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция универсальных значений\n",
    "def unique_check(df: object, directory = '', name_to_save = 'unique_data.csv'):\n",
    "\n",
    "    unique_columns = {}\n",
    "\n",
    "    for column in df.columns:\n",
    "        unique_values = df[column].drop_duplicates().dropna().tolist()\n",
    "        unique_columns[column] = unique_values\n",
    "\n",
    "    # Найдем максимальную длину среди всех списков уникальных значений\n",
    "    max_length = max(len(values) for values in unique_columns.values())\n",
    "\n",
    "    # Создадим новый словарь с выровненными списками\n",
    "    aligned_columns = {}\n",
    "    for column, values in unique_columns.items():\n",
    "        \n",
    "        # Заполним недостающие места значением NaN\n",
    "        aligned_values = values + [None]*(max_length - len(values))\n",
    "        aligned_columns[column] = aligned_values\n",
    "\n",
    "    # Создадим новый DataFrame\n",
    "    unique_df = pd.DataFrame(aligned_columns).T\n",
    "\n",
    "    # Сохранение в новый CSV файл\n",
    "    unique_df.to_csv(directory + name_to_save)\n",
    "    print(\"Уникальные значения сохранены в '{}'\".format(directory + name_to_save))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total_df = pd.DataFrame()\n",
    "\n",
    "# list_regions = ['params_m.json', 'params_mo.json', 'params_spb.json', 'params_lo.json']\n",
    "# for name in list_regions:\n",
    "#     df = pd.read_json(json_directory + name).T.reset_index()\n",
    "#     df = df.rename(columns={'index':'ЖК'})\n",
    "\n",
    "#     total_df = pd.concat([total_df, df], ignore_index=True)\n",
    "\n",
    "# total_df.to_csv(dcsv_directory + 'params_all_regions.csv')\n",
    "# unique_check(total_df, dcsv_directory, 'total_unique_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Преобразование текстовых параметров в числовые (\"эмбеддинг\")  \n",
    "Необходимый этап, поскольку данные из ЕРЗ не представляются сразу в измеримых величинах (ниже показано)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.0 Репрезентация уникальных значений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unique = pd.read_csv(dcsv_directory + 'total_unique_data.csv')\n",
    "df_unique = df_unique.rename(columns={'Unnamed: 0': 'Параметр'})\n",
    "\n",
    "df_unique.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пояснение: для любого параметра можно заметить, что он состоит из двух элементов:\n",
    "- Метрика - имеет категориальный/текстовый формат, который описывает значение параметра (\"средний\"/\"малый\", \"от ... до ...\" и проч.);  \n",
    "- Оценка - имеет числовой формат.  \n",
    "\n",
    "Необходимо их разделить друг от друга + преобразовать метрику в число."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.1 Обработка данных посредством разделения \"метрик\" и \"оценок\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "===============================================================================\n",
    "Эмбеддинг\n",
    "===============================================================================\n",
    "'''\n",
    "class EmbeddingByHands():\n",
    "    \n",
    "    # ------------------------------------------------------------------------\n",
    "    ''' ПРЕДВАРИТЕЛЬНАЯ ПОДГОТОВКА '''\n",
    "    def __init__(self, name_change: str, name_reference: str, directory_change = '', directory_reference = ''):\n",
    "        self.table_to_change = pd.read_csv(directory_change + name_change, encoding='utf-8')\n",
    "        self.reference_table = pd.read_csv(directory_reference + name_reference, encoding='utf-8')\n",
    "        \n",
    "        \n",
    "    # ------------------------------------------------------------------------\n",
    "    ''' ФУНЦИЯ ПРОВЕРКИ НА ТО, ЧТО СТРОКА ЯВЛЯЕТСЯ ЧИСЛОМ '''\n",
    "    def _is_number(self, string: str) -> bool:\n",
    "        try:\n",
    "            float(string.replace(',', '.'))\n",
    "            return True\n",
    "        \n",
    "        except (ValueError, TypeError):\n",
    "            return False\n",
    "        \n",
    "    \n",
    "    # ------------------------------------------------------------------------\n",
    "    ''' ФУНКЦИЯ НОРМАЛИЗАЦИИ ТЕКСТА ДЛЯ ПОВЫШЕНИЯ НАДЁЖНОСТИ СРАВНЕНИЯ '''\n",
    "    def _normalize_text(self, text: str) -> str:\n",
    "        if not isinstance(text, str):\n",
    "            return ''\n",
    "    \n",
    "        # Приводим к нижнему регистру и удаляем лишние пробелы\n",
    "        text = text.lower().strip()\n",
    "        text = re.sub(r'\\s+', ' ', text)\n",
    "    \n",
    "        # Заменяем запятые на точки в числах\n",
    "        text = re.sub(r'(\\d),(\\d)', r'\\1.\\2', text)\n",
    "    \n",
    "        return text\n",
    "    \n",
    "    \n",
    "    # ------------------------------------------------------------------------\n",
    "    ''' ФУНКЦИЯ РАЗДЕЛЕНИЯ МЕТРИКИ И ОЦЕНКИ '''\n",
    "    def _split_metric_rating(self, cell_value: object):\n",
    "\n",
    "        if not isinstance(cell_value, str) or cell_value.strip() == '':\n",
    "            return None, None\n",
    "    \n",
    "        # Разделяем строку по пробелам\n",
    "        parts = cell_value.strip().split()\n",
    "    \n",
    "        # Проверяем, что последняя часть - это число (оценка)\n",
    "        if parts and self._is_number(parts[-1]):\n",
    "            rating = float(parts[-1].replace(',', '.'))\n",
    "            metric = ' '.join(parts[:-1])\n",
    "            return metric, rating\n",
    "    \n",
    "        return cell_value, None\n",
    "    \n",
    "    \n",
    "    # ------------------------------------------------------------------------\n",
    "    ''' ФУНКЦИЯ СОЗДАНИЯ СЛОВАРЯ СООТВЕТСТВИЯ МЕТРИК И ЧИСЛОВЫХ ЗНАЧЕНИЙ НА ОСНОВЕ СПРАВОЧНОЙ ТАБЛИЦЫ '''\n",
    "    def _build_metric_mapping_from_reference(self) -> dict:\n",
    "        \n",
    "        try:\n",
    "            # Загружаем справочную таблицу\n",
    "            df = self.reference_table\n",
    "        \n",
    "            # Создаем словарь для хранения соответствий\n",
    "            metric_mapping = {}\n",
    "        \n",
    "            # Обрабатываем каждую строку таблицы (параметр)\n",
    "            for row_idx in range(df.shape[0]):\n",
    "                parameter = df.iloc[row_idx, 0]  # Название параметра\n",
    "                normalized_parameter = self._normalize_text(parameter)\n",
    "                \n",
    "                # Создаем вложенный словарь для этого параметра\n",
    "                if normalized_parameter not in metric_mapping:\n",
    "                    metric_mapping[normalized_parameter] = {}\n",
    "                \n",
    "                # Обрабатываем каждое возможное значение параметра\n",
    "                for col_idx in range(1, df.shape[1]):\n",
    "                    cell_value = df.iloc[row_idx, col_idx]\n",
    "                    \n",
    "                    if pd.isna(cell_value) or cell_value == '':\n",
    "                        continue\n",
    "                    \n",
    "                    # Разделяем метрику и оценку\n",
    "                    metric, rating = self._split_metric_rating(str(cell_value))\n",
    "                    \n",
    "                    if metric:\n",
    "                        # Нормализуем метрику для более надежного сравнения\n",
    "                        normalized_metric = self._normalize_text(metric)\n",
    "                        \n",
    "                        # Запоминаем соответствие (используем позицию в таблице)\n",
    "                        metric_mapping[normalized_parameter][normalized_metric] = col_idx\n",
    "            \n",
    "            return metric_mapping\n",
    "    \n",
    "        except Exception as e:\n",
    "            print(f'Ошибка при создании словаря соответствий: {e}')\n",
    "            return {}\n",
    "\n",
    "\n",
    "    # ------------------------------------------------------------------------\n",
    "    ''' ФУНКЦИЯ ПРЕОБРАЗОВАНИЯ ТЕКСТОВОЙ МЕТРИКИ В ЧИСЛОВОЕ ЗНАЧЕНИЕ С УЧЁТОМ ПАРАМЕТРА И СПРАВОЧНОЙ ТАБЛИЦЫ '''\n",
    "    def _convert_metric_to_numeric(self, metric, parameter=None, metric_mapping=None):\n",
    "        \n",
    "        if not isinstance(metric, str) or metric.strip() == '':\n",
    "            return None\n",
    "    \n",
    "        original_metric = metric.strip()\n",
    "        normalized_metric = self._normalize_text(original_metric)\n",
    "        \n",
    "        # Если есть словарь соответствий и известен параметр, пытаемся использовать его\n",
    "        if metric_mapping and parameter:\n",
    "            normalized_parameter = self._normalize_text(parameter)\n",
    "            \n",
    "            if normalized_parameter in metric_mapping and normalized_metric in metric_mapping[normalized_parameter]:\n",
    "                return metric_mapping[normalized_parameter][normalized_metric]\n",
    "    \n",
    "        # Если не удалось найти соответствие в словаре, используем общую логику\n",
    "        # Качественные оценки\n",
    "        if normalized_metric in [\"низкий\", \"плохой\", \"минимальный\"]:\n",
    "            return 1\n",
    "        elif normalized_metric == \"средний\":\n",
    "            return 2\n",
    "        elif normalized_metric in [\"высокий\", \"хороший\", \"максимальный\"]:\n",
    "            return 3\n",
    "        elif normalized_metric in [\"нет\", \"отсутствует\", \"нет подземного паркинга\", \"нет лифта\"]:\n",
    "            return 0\n",
    "        elif normalized_metric in [\"есть\", \"да\", \"имеется\"]:\n",
    "            return 1\n",
    "        \n",
    "        # Диапазоны значений (\"от ... до\")\n",
    "        range_match = re.search(r'от\\s+(\\d+[.,]?\\d*)\\s+до\\s+(\\d+[.,]?\\d*)', normalized_metric)\n",
    "        if range_match:\n",
    "            lower = float(range_match.group(1).replace(',', '.'))\n",
    "            upper = float(range_match.group(2).replace(',', '.'))\n",
    "            return (lower + upper) / 2\n",
    "        \n",
    "        # \"менее X\"\n",
    "        less_match = re.search(r'менее\\s+(\\d+[.,]?\\d*)', normalized_metric)\n",
    "        if less_match:\n",
    "            value = float(less_match.group(1).replace(',', '.'))\n",
    "            return value / 2\n",
    "        \n",
    "        # \"более X\"\n",
    "        more_match = re.search(r'более\\s+(\\d+[.,]?\\d*)', normalized_metric)\n",
    "        if more_match:\n",
    "            value = float(more_match.group(1).replace(',', '.'))\n",
    "            return value * 1.5\n",
    "    \n",
    "        # Числовые значения с единицами измерения\n",
    "        num_match = re.search(r'(\\d+[.,]?\\d*)\\s*(?:м|метров|км)?', normalized_metric)\n",
    "        if num_match:\n",
    "            return float(num_match.group(1).replace(',', '.'))\n",
    "    \n",
    "    \n",
    "    # ------------------------------------------------------------------------\n",
    "    ''' ФУНКЦИЯ ОБРАБОТКИ CSV-ФАЙЛА И СОЗДАНИЕ НОВОГО DATAFRAME С РАЗДЕЛЁННЫМИ МЕТРИКАМИ И ОЦЕНКАМИ '''\n",
    "    def _process_csv(self):\n",
    "        \n",
    "        try:\n",
    "            # Создаем словарь соответствий на основе справочной таблицы\n",
    "            metric_mapping = self._build_metric_mapping_from_reference()\n",
    "            \n",
    "            # Загружаем данные\n",
    "            df = self.table_to_change\n",
    "                        \n",
    "            # Создаем новый DataFrame для результатов\n",
    "            result_df = pd.DataFrame()\n",
    "        \n",
    "            # Копируем названия ЖК в результирующий DataFrame\n",
    "            if df.shape[0] > 0:\n",
    "                result_df['ЖК'] = df.iloc[:, 0]\n",
    "        \n",
    "            # Обрабатываем каждый столбец данных (параметр)\n",
    "            for col_idx, col_name in enumerate(df.columns[1:], 1):\n",
    "                # Временные списки для метрик, числовых метрик и оценок\n",
    "                metrics = []\n",
    "                numeric_metrics = []\n",
    "                ratings = []\n",
    "            \n",
    "                # Обрабатываем каждую ячейку в столбце\n",
    "                for row_idx in range(df.shape[0]):\n",
    "                    cell_value = df.iloc[row_idx, col_idx]\n",
    "                    metric, rating = self._split_metric_rating(str(cell_value))\n",
    "                    numeric_metric = self._convert_metric_to_numeric(metric, col_name, metric_mapping)\n",
    "                \n",
    "                    metrics.append(metric)\n",
    "                    numeric_metrics.append(numeric_metric)\n",
    "                    ratings.append(rating)\n",
    "            \n",
    "                # Добавляем результаты в итоговый DataFrame\n",
    "                result_df[f'{col_name}_метрика'] = metrics\n",
    "                result_df[f'{col_name}_числовая_метрика'] = numeric_metrics\n",
    "                result_df[f'{col_name}_оценка'] = ratings\n",
    "        \n",
    "            return result_df\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f'Ошибка при обработке файла: {e}')\n",
    "            return pd.DataFrame()\n",
    "        \n",
    "    \n",
    "    # ------------------------------------------------------------------------\n",
    "    ''' ФУНКЦИЯ ОБРАБОТКИ CSV-ФАЙЛА И СОЗДАНИЕ НОВОГО DATAFRAME В ДЛИННОМ ФОРМАТЕ '''\n",
    "    def _process_csv_long_format(self):\n",
    "        \n",
    "        try:\n",
    "            # Создаем словарь соответствий на основе справочной таблицы\n",
    "            metric_mapping = self._build_metric_mapping_from_reference()\n",
    "        \n",
    "            # Загружаем данные\n",
    "            df = self.table_to_change\n",
    "        \n",
    "            # Создаем списки для длинного формата\n",
    "            rows = []\n",
    "        \n",
    "            # Обрабатываем каждую строку (ЖК)\n",
    "            for row_idx in range(df.shape[0]):\n",
    "                zhk_name = df.iloc[row_idx, 0]\n",
    "            \n",
    "                # Обрабатываем каждый параметр для данного ЖК\n",
    "                for col_idx, param_name in enumerate(df.columns[1:], 1):\n",
    "                    cell_value = df.iloc[row_idx, col_idx]\n",
    "                    metric, rating = self._split_metric_rating(str(cell_value))\n",
    "                    numeric_metric = self._convert_metric_to_numeric(metric, param_name, metric_mapping)\n",
    "                \n",
    "                    # Добавляем строку в результат\n",
    "                    rows.append({\n",
    "                        'ЖК': zhk_name,\n",
    "                        'Параметр': param_name,\n",
    "                        'Метрика': metric,\n",
    "                        'Числовая_метрика': numeric_metric,\n",
    "                        'Оценка': rating\n",
    "                    })\n",
    "        \n",
    "            return pd.DataFrame(rows)\n",
    "    \n",
    "        except Exception as e:\n",
    "            print(f'Ошибка при обработке файла: {e}')\n",
    "            return pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Запуск класса обработки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed = EmbeddingByHands('params_all_regions.csv', 'total_unique_data.csv', directory_change=dcsv_directory, directory_reference=dcsv_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обработка в широком формате\n",
    "result_wide_df = embed._process_csv()\n",
    "    \n",
    "# Обработка в длинном формате\n",
    "# result_long_df = embed._process_csv_long_format()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.2 Дополнительные корректировки перед сохранением"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wide_total = result_wide_df.drop(columns=['ЖК', 'ЖК_числовая_метрика', 'ЖК_оценка'])\n",
    "wide_total = wide_total.rename(columns={'ЖК_метрика': 'ЖК'})\n",
    "\n",
    "wide_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_metrics_numb = ['ЖК']\n",
    "cols_values = ['ЖК']\n",
    "\n",
    "cols_metrics_rename = {}\n",
    "cols_values_rename = {}\n",
    "\n",
    "i_met = 0\n",
    "i_est = 0\n",
    "\n",
    "# Цикл отбора параметров для двух типов таблиц\n",
    "for col in wide_total.columns:\n",
    "    if col.endswith('числовая_метрика'):\n",
    "        cols_metrics_numb.append(col)\n",
    "        \n",
    "        i_met += 1\n",
    "        cols_metrics_rename[col] = 'X_{}'.format(i_met)\n",
    "        \n",
    "    elif col.endswith('оценка'):\n",
    "        cols_values.append(col)\n",
    "        \n",
    "        i_est += 1\n",
    "        cols_values_rename[col] = 'X_{}'.format(i_est)\n",
    "        \n",
    "# Создание новых таблиц данных, переименовывание и их сохранение\n",
    "X_metrics = wide_total[cols_metrics_numb]\n",
    "X_metrics = X_metrics.rename(columns=cols_metrics_rename)\n",
    "\n",
    "X_values = wide_total[cols_values]\n",
    "X_values = X_values.rename(columns=cols_values_rename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сохранение таблиц\n",
    "X_metrics.to_csv(data_clean_directory + 'ERZ_X_metrics.csv', index=False, encoding='utf-8')\n",
    "X_values.to_csv(data_clean_directory + 'ERZ_X_values.csv', index=False, encoding='utf-8')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
